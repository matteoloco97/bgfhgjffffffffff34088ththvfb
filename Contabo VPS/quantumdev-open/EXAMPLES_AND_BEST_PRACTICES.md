# ğŸ’¡ EXAMPLES AND BEST PRACTICES - QuantumDev Max

Esempi pratici e best practices per sfruttare al meglio QuantumDev Max.

---

## ğŸ“‘ Indice

1. [Esempi Conversational Memory](#-conversational-memory)
2. [Esempi Function Calling](#-function-calling)
3. [Esempi Reasoning Traces](#-reasoning-traces)
4. [Esempi Artifacts](#-artifacts)
5. [Patterns Avanzati](#-patterns-avanzati)
6. [Best Practices](#-best-practices)
7. [Anti-Patterns da Evitare](#-anti-patterns)

---

## ğŸ§  Conversational Memory

### Esempio 1: Multi-turn Code Development

```
ğŸ‘¤ User: Devo creare un'API REST per un todo app

ğŸ¤– Jarvis: Perfetto! Quale framework preferisci? Ho esperienza con FastAPI, 
   Flask, Express.js, Django REST...

ğŸ‘¤ User: FastAPI

ğŸ¤– Jarvis: Ottimo. E per il database? Posso suggerirti SQLite per sviluppo 
   locale, PostgreSQL per produzione, o MongoDB se preferisci NoSQL.

ğŸ‘¤ User: SQLite va bene per ora

ğŸ¤– Jarvis: [RICORDA: FastAPI + SQLite]
   Ecco la struttura base:
   
   [Creates code artifact with full CRUD API]
   
   Vuoi che aggiunga autenticazione JWT?
   
ğŸ‘¤ User: SÃ¬, e anche i test

ğŸ¤– Jarvis: [RICORDA: vuole auth + test]
   Aggiungo:
   1. Auth JWT con python-jose
   2. Test con pytest + httpx
   
   [Creates updated artifact]
```

**Cosa succede dietro:**
- Sessione salvata con tutti i turni
- Contesto mantenuto attraverso la conversazione
- Auto-summarization se supera 20 turni

---

### Esempio 2: Research con Memoria

```
ğŸ‘¤ User: Sto studiando transformer architecture

ğŸ¤– Jarvis: I Transformer sono un'architettura rivoluzionaria introdotta 
   nel paper "Attention Is All You Need" (2017)...
   
   [Salva in memoria: utente studia transformers]

ğŸ‘¤ User: Spiegami il meccanismo di attention

ğŸ¤– Jarvis: [Recall: sta studiando transformers]
   L'attention mechanism nei Transformer funziona cosÃ¬:
   - Query, Key, Value vectors
   - Scaled dot-product attention
   - Multi-head attention per catturare diverse relazioni...

ğŸ‘¤ User: Come si collega a BERT?

ğŸ¤– Jarvis: [Recall: transformers, attention]
   BERT usa l'encoder dei Transformer:
   - Bidirectional (vs GPT che Ã¨ unidirettional)
   - Masked Language Model per pre-training...
   
   Vuoi che ti spieghi le differenze con GPT?
```

---

### Esempio 3: Preferenze Persistenti

```
ğŸ‘¤ User: Preferisco risposte brevi e in italiano

ğŸ¤– Jarvis: [Salva preferenza: risposte brevi, italiano]
   Perfetto! D'ora in poi sarÃ² conciso.

[... 2 giorni dopo ...]

ğŸ‘¤ User: Explain machine learning

ğŸ¤– Jarvis: [Recall: preferisce italiano, risposte brevi]
   Il Machine Learning Ã¨ l'apprendimento automatico: 
   algoritmi che migliorano con l'esperienza sui dati.
   
   Tre tipi principali:
   â€¢ Supervised: impara da esempi etichettati
   â€¢ Unsupervised: trova pattern nei dati
   â€¢ Reinforcement: impara da feedback
```

---

## ğŸ”§ Function Calling

### Esempio 1: Multi-tool Automatico

```
ğŸ‘¤ User: Quanto costa Bitcoin adesso e calcola quanto varrebbe investire â‚¬1000

ğŸ¤– Jarvis: [Analisi: serve prezzo BTC + calcolo]
   
   [Tool: price_lookup] â†’ BTC = $42,500
   [Tool: calculator] â†’ â‚¬1000 * (1/42500) = 0.0235 BTC
   
   Bitcoin Ã¨ a $42,500. Con â‚¬1000 (â‰ˆ$1,100) potresti comprare 
   circa 0.026 BTC.

ğŸ‘¤ User: E se investissi in ETH invece?

ğŸ¤– Jarvis: [Recall: sta confrontando crypto]
   
   [Tool: price_lookup] â†’ ETH = $2,200
   [Tool: calculator] â†’ $1100 / 2200 = 0.5 ETH
   
   Con lo stesso importo compreresti 0.5 ETH.
   
   Confronto:
   â€¢ BTC: 0.026 coin
   â€¢ ETH: 0.5 coin
   
   ETH ti dÃ  piÃ¹ "unitÃ " ma il valore Ã¨ equivalente.
```

---

### Esempio 2: Research + Code

```
ğŸ‘¤ User: Cerca le best practices per async Python e scrivi un esempio

ğŸ¤– Jarvis: [Analisi: web_search + code_generator]
   
   [Tool: web_search] â†’ Found 5 sources on async Python
   [Tool: code_generator] â†’ Creating example
   
   Best practices da fonti autorevoli:
   1. Usa `asyncio.gather()` per task paralleli
   2. Evita blocking I/O nel event loop
   3. Usa context managers con `async with`
   
   ğŸ“¦ Artifact: async_example.py
   ```python
   import asyncio
   import aiohttp
   
   async def fetch_url(session, url):
       async with session.get(url) as response:
           return await response.json()
   
   async def main():
       urls = ['https://api1.example', 'https://api2.example']
       async with aiohttp.ClientSession() as session:
           results = await asyncio.gather(*[
               fetch_url(session, url) for url in urls
           ])
       return results
   
   if __name__ == "__main__":
       asyncio.run(main())
   ```
```

---

### Esempio 3: Scheduled Task

```
ğŸ‘¤ User: A che ora gioca la Juve domani e dammi le quote

ğŸ¤– Jarvis: [Analisi: schedule_lookup + potenzialmente betting data]
   
   [Tool: schedule_lookup] â†’ Juventus vs Milan, 20:45
   [Tool: web_search] â†’ Odds: Juve 2.10, Draw 3.40, Milan 3.50
   
   ğŸ“… Juventus vs Milan
   ğŸ• Domani ore 20:45
   
   Quote (indicative):
   â€¢ Juventus: 2.10
   â€¢ Pareggio: 3.40
   â€¢ Milan: 3.50
   
   âš ï¸ Le quote cambiano in tempo reale, verifica sul bookmaker.
```

---

## ğŸ’­ Reasoning Traces

### Esempio: Debug Trasparente

```
ğŸ‘¤ User: /think PerchÃ© il prezzo di Bitcoin Ã¨ volatile?

ğŸ¤– Jarvis: 
   ğŸ§  **Reasoning Trace**
   
   ğŸ” **Analysis** (12ms)
   Query richiede spiegazione economica/finanziaria.
   Non serve web search, Ã¨ conoscenza generale.
   
   ğŸ“‹ **Planning** (5ms)
   Strategia: DIRECT_LLM con conoscenza economica.
   
   âš¡ **Execution** (0ms)
   Nessun tool necessario.
   
   âœ¨ **Synthesis** (845ms)
   Generazione risposta...
   
   âœ… **Total: 862ms**
   
   ğŸ“ **Response:**
   Bitcoin Ã¨ volatile per diversi fattori:
   
   1. **Supply limitata** (21M max) amplifica movimenti
   2. **Mercato giovane** con meno liquiditÃ 
   3. **Speculazione** alta percentuale di trading
   4. **News-driven** reazioni forti a notizie
   5. **Whale movements** grandi holder muovono il mercato
```

---

### Esempio: Tool Chain Visibility

```
ğŸ‘¤ User: /think Confronta meteo Roma vs Milano oggi

ğŸ¤– Jarvis:
   ğŸ§  **Reasoning Trace**
   
   ğŸ” **Analysis** (15ms)
   Query richiede dati live da 2 cittÃ .
   Tool: weather (x2, parallel)
   
   ğŸ“‹ **Planning** (8ms)
   Strategia: TOOL_ASSISTED
   Tools: weather(Roma), weather(Milano) in parallelo
   
   âš¡ **Execution** (1250ms)
   â€¢ weather(Roma) â†’ â˜€ï¸ 18Â°C
   â€¢ weather(Milano) â†’ ğŸŒ§ï¸ 12Â°C
   
   ğŸ¤” **Reflection** (5ms)
   Entrambi i tool hanno risposto, dati completi.
   
   âœ¨ **Synthesis** (320ms)
   Costruzione tabella comparativa...
   
   âœ… **Total: 1598ms**
   
   ğŸ“ **Response:**
   | CittÃ  | Temp | Condizioni |
   |-------|------|------------|
   | Roma | 18Â°C | â˜€ï¸ Sole |
   | Milano | 12Â°C | ğŸŒ§ï¸ Pioggia |
   
   Roma Ã¨ piÃ¹ calda di 6Â°C oggi!
```

---

## ğŸ“¦ Artifacts

### Esempio 1: Code Artifact

```
ğŸ‘¤ User: Scrivi una classe Python per gestire una coda prioritaria

ğŸ¤– Jarvis:
   ğŸ“¦ **Priority Queue Implementation** (v1)
   Type: code | Language: python
   
   ```python
   import heapq
   from typing import Any, Optional
   from dataclasses import dataclass, field
   
   @dataclass(order=True)
   class PriorityItem:
       priority: int
       item: Any = field(compare=False)
   
   class PriorityQueue:
       def __init__(self):
           self._heap: list = []
           self._counter = 0
       
       def push(self, item: Any, priority: int = 0) -> None:
           heapq.heappush(self._heap, PriorityItem(priority, item))
           self._counter += 1
       
       def pop(self) -> Optional[Any]:
           if self._heap:
               return heapq.heappop(self._heap).item
           return None
       
       def peek(self) -> Optional[Any]:
           return self._heap[0].item if self._heap else None
       
       def __len__(self) -> int:
           return len(self._heap)
       
       def __bool__(self) -> bool:
           return bool(self._heap)
   ```
   
   Artifact ID: `art_a1b2c3d4e5f6`
   
   Vuoi che aggiunga metodi per update priority?
```

---

### Esempio 2: Table Artifact

```
ğŸ‘¤ User: Crea una tabella comparativa GPU per ML

ğŸ¤– Jarvis:
   ğŸ“¦ **GPU Comparison for ML** (v1)
   Type: table
   
   | GPU | VRAM | Tensor Cores | Price | Best For |
   |-----|------|--------------|-------|----------|
   | RTX 3090 | 24GB | 328 | $1,500 | Training medium models |
   | RTX 4090 | 24GB | 512 | $1,600 | Fast inference |
   | A100 | 40/80GB | 432 | $10,000+ | Enterprise training |
   | RTX 8000 | 48GB | 576 | $5,500 | Large models, budget |
   | H100 | 80GB | 528 | $25,000+ | State-of-art training |
   
   Artifact ID: `art_x1y2z3w4v5u6`
   
   Per QuantumDev Max, la RTX 8000 con 48GB VRAM Ã¨ ottimale
   per Qwen 32B AWQ.
```

---

### Esempio 3: JSON Artifact

```
ğŸ‘¤ User: Genera lo schema JSON per un'API di e-commerce

ğŸ¤– Jarvis:
   ğŸ“¦ **E-commerce API Schema** (v1)
   Type: json | Language: json
   
   ```json
   {
     "openapi": "3.0.0",
     "info": {
       "title": "E-commerce API",
       "version": "1.0.0"
     },
     "paths": {
       "/products": {
         "get": {
           "summary": "List products",
           "parameters": [
             {"name": "category", "in": "query", "type": "string"},
             {"name": "limit", "in": "query", "type": "integer"}
           ],
           "responses": {
             "200": {
               "description": "Product list",
               "content": {
                 "application/json": {
                   "schema": {
                     "type": "array",
                     "items": {"$ref": "#/components/schemas/Product"}
                   }
                 }
               }
             }
           }
         }
       }
     },
     "components": {
       "schemas": {
         "Product": {
           "type": "object",
           "properties": {
             "id": {"type": "string"},
             "name": {"type": "string"},
             "price": {"type": "number"},
             "category": {"type": "string"}
           }
         }
       }
     }
   }
   ```
   
   Artifact ID: `art_j1k2l3m4n5o6`
```

---

## ğŸ¯ Patterns Avanzati

### Pattern 1: Progressive Refinement

```
ğŸ‘¤ User: Crea un sito web

ğŸ¤– Jarvis: Per cosa ti serve? Portfolio, e-commerce, blog, landing page...?

ğŸ‘¤ User: Portfolio per sviluppatore

ğŸ¤– Jarvis: Vuoi qualcosa di minimale o con animazioni?
   Tech stack: HTML/CSS puro, React, Vue, Next.js...?

ğŸ‘¤ User: Minimale, HTML/CSS

ğŸ¤– Jarvis: [Creates artifact: portfolio_base.html]
   
   Ecco la struttura base. Sezioni incluse:
   â€¢ Hero con nome e tagline
   â€¢ About me
   â€¢ Skills (con progress bars)
   â€¢ Projects gallery
   â€¢ Contact form
   
   Vuoi che aggiunga dark mode toggle?
```

---

### Pattern 2: Context Switching

```
ğŸ‘¤ User: Sto lavorando su un progetto Python

ğŸ¤– Jarvis: [Salva contesto: progetto Python attivo]
   OK, dimmi di piÃ¹. Che tipo di progetto?

ğŸ‘¤ User: Un bot Telegram

ğŸ¤– Jarvis: [Update: bot Telegram in Python]
   Ottimo! Stai usando python-telegram-bot o aiogram?

[... dopo 1 ora, nuova sessione ...]

ğŸ‘¤ User: Riprendiamo

ğŸ¤– Jarvis: [Recall: bot Telegram Python]
   Certo! Stavamo parlando del tuo bot Telegram in Python.
   Dove eravamo rimasti?
```

---

### Pattern 3: Error Recovery

```
ğŸ‘¤ User: Quanto costa dogecoin?

ğŸ¤– Jarvis: [Tool: price_lookup("DOGE")]
   âŒ API timeout
   
   [Retry 1/2]
   âŒ API error
   
   [Fallback: web_search("dogecoin price")]
   âœ… Found price from CoinGecko
   
   DOGE Ã¨ a circa $0.08 (dato da web search, non real-time API).
   âš ï¸ Il servizio prezzi Ã¨ temporaneamente lento.
```

---

## âœ… Best Practices

### 1. Conversazioni Strutturate

```
âŒ BAD: "fammi vedere come si fa quella cosa"

âœ… GOOD: "Mostrami come implementare autenticazione JWT in FastAPI"
```

### 2. Contesto Esplicito

```
âŒ BAD: "aggiungi i test"

âœ… GOOD: "Aggiungi test pytest per l'API FastAPI che abbiamo creato prima"
```

### 3. Feedback per Miglioramento

```
âŒ BAD: "non funziona"

âœ… GOOD: "Il codice dÃ  questo errore: TypeError: 'str' object is not callable"
```

### 4. Sfrutta la Memoria

```
âœ… "Come abbiamo discusso prima..."
âœ… "Ricordi la funzione di sorting?"
âœ… "Continua con lo stesso stile"
```

### 5. Usa i Comandi Avanzati

```
/think <query>      # Vedere il ragionamento
/context            # Verificare lo stato sessione
/artifacts          # Gestire i contenuti salvati
/reset              # Ricominciare da zero
```

---

## âŒ Anti-Patterns

### 1. Troppe Query Sconnesse

```
âŒ 
"Meteo Roma"
"Scrivi codice Python"
"Prezzo BTC"
"Qual Ã¨ la capitale della Francia"
"Debug questo errore"

â†’ La memoria si frammenta, perde coerenza
```

### 2. Query Troppo Vaghe

```
âŒ "Aiutami"
âŒ "Cosa devo fare?"
âŒ "Dimmi qualcosa"

â†’ Tool selection confusa, risposte generiche
```

### 3. Ignorare il Contesto

```
âŒ Ripetere sempre tutto il contesto
âœ… "Come prima, ma con X diverso"
```

### 4. Session Infinite

```
âŒ Non fare mai /reset
â†’ Context troppo lungo, summarization eccessiva

âœ… /reset quando cambi progetto completamente
```

### 5. Aspettarsi Persistenza Eterna

```
âŒ Aspettarsi che ricordi conversazioni di 2 mesi fa
â†’ TTL Ã¨ 7 giorni

âœ… Per info permanenti, salva in ChromaDB via /memory/fact
```

---

## ğŸ“Š Performance Tips

1. **Parallel Queries**: Le query multi-tool beneficiano da parallelizzazione
2. **Sliding Window**: Mantieni conversazioni focused per migliore contesto
3. **Artifacts**: Salva codice lungo come artifact invece di re-generare
4. **Summarization**: Lascia che il sistema auto-riassuma dopo 20 turni

---

## ğŸš€ Quick Reference

| Vuoi... | Comando/Azione |
|---------|----------------|
| Vedere il pensiero | `/think <query>` |
| Stato sessione | `/context` |
| Lista artifacts | `/artifacts` |
| Vedere artifact | `/artifact <id>` |
| Reset memoria | `/reset` |
| Ricerca web | `/web <query>` |
| Leggere URL | `/read <url>` |

---

**QuantumDev Max - Make the most of it!** ğŸš€
